{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aeaf86-c2d4-405b-b374-b905fbea1f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a181c1-70ac-49b2-94ff-0ea12016a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c014e-c5e7-4b00-b2bd-f20ea0ffff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, geojson\n",
    "import random, scipy\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, MultiPoint, shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import shapely\n",
    "from shapely.ops import transform\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a8b57-2583-4aa6-8490-f885ad739d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'https://api.gbif.org/v1/occurrence/search/'\n",
    "DATASETKEY = '50c9509d-22c7-4a22-a47d-8c48425ef4a7'  # iNaturalist research-grade observations\n",
    "TAXONKEYS = {'Arthropoda': '54', 'Aves': '212', 'Tracheophyta': '7707728'}\n",
    "\n",
    "STARTYEAR = '2016'\n",
    "ENDYEAR = '2021'\n",
    "\n",
    "LIMIT = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c07edee-bdbc-47e9-9490-0a0c93f83aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-indicators'\n",
    "aws_s3_dir = \"https://\"+bucket_name+\".s3.eu-west-3.amazonaws.com\"\n",
    "boundary_ext = '/data/boundaries/'\n",
    "indicators_file_aws = 'indicators/indicators.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667abf1c-7d80-4afa-9b61-37419706b6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get list of cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir + boundary_ext + 'boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6946dc-b73c-44b9-80cc-562d0db945c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingbox_wkt(p):\n",
    "    # Returns WKT for bounding box.\n",
    "    # Necessary because GBIF API won't accept complex polygons.\n",
    "    minx, miny, maxx, maxy = p.bounds\n",
    "    return 'POLYGON (({0} {3}, {0} {2}, {1} {2}, {0} {3}))'.format(str(minx), str(maxx), str(miny), str(maxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182c612-3bae-4618-950e-8ee622d6f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573580c6-e545-49df-9d8c-f27d3599f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_geom(poly, taxonname, boundary_id):\n",
    "    print(boundary_id, taxonname)\n",
    "    observations = []\n",
    "    \n",
    "    if poly.type == 'MultiPolygon':\n",
    "        poly = unary_union(poly)\n",
    "    \n",
    "    if str(poly) != 'GEOMETRYCOLLECTION EMPTY':\n",
    "        box = boundingbox_wkt(poly)\n",
    "\n",
    "        offset = -LIMIT\n",
    "        while offset == -LIMIT or not results['endOfRecords']:\n",
    "            offset += LIMIT\n",
    "            url = '{0}?dataset_key={1}&taxon_key={2}&year={3},{4}&geometry={5}&limit={6}&offset={7}&hasCoordinate=true'.format(API_URL, DATASETKEY, TAXONKEYS[taxonname], STARTYEAR, ENDYEAR, box, LIMIT, offset)\n",
    "            resp = requests.get(url)\n",
    "            results = resp.json()\n",
    "            print('  {0}: {1}/{2}'.format(taxonname, results['offset'], results['count']))\n",
    "            # Note spatial subsetting of points happens below (twice) as part of the conditions in the list comprehensions\n",
    "            observations += [{\n",
    "                'species': i['species'],\n",
    "                'lat': i['decimalLatitude'],  # We don't really need to save lat/lon for this\n",
    "                'lon': i['decimalLongitude'],\n",
    "            } for i in results['results'] if 'species' in i.keys() and Point(float(i['decimalLongitude']), float(i['decimalLatitude'])).within(poly)]\n",
    "        g = gpd.GeoDataFrame(geometry=[Point(i['lon'], i['lat']) for i in observations])\n",
    "        g['species'] = [i['species'] for i in observations]\n",
    "        filepath = \"data/{1}-{0}-2016-2021.geojson\".format(taxonname, boundary_id) # local folder must already exist or be created manually before running. \n",
    "        g.to_file(filepath, driver='GeoJSON')\n",
    "\n",
    "        # upload in s3\n",
    "        s3.meta.client.upload_file(\n",
    "            filepath, \n",
    "            bucket_name, \n",
    "            'data/biodiversity/GBIF/{0}_observations/{1}-{0}-2016-2021.geojson'.format(taxonname, boundary_id),\n",
    "            ExtraArgs={'ACL':'public-read'}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3af511-c436-450f-8040-a644b373153d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download extracts and upload to AWS\n",
    "\n",
    "for i in range(len(boundary_georef)):\n",
    "    boundary_id = boundary_georef.loc[i, 'geo_name']+'-' + boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    temp_gdf = gpd.GeoDataFrame.from_features(boundary_geo)\n",
    "    for taxonname in TAXONKEYS:\n",
    "        do_one_geom(temp_gdf.iloc[0]['geometry'], taxonname, boundary_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f672e-79e3-48b9-ac54-c3363cfdda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
