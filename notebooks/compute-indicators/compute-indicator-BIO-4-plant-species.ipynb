{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aeaf86-c2d4-405b-b374-b905fbea1f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap\n",
    "# !{sys.executable} -m pip install --extra-index-url https://artifactory.vgt.vito.be/api/pypi/python-packages/simple terracatalogueclient\n",
    "# !{sys.executable} -m pip install pip rasterstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a181c1-70ac-49b2-94ff-0ea12016a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290c014e-c5e7-4b00-b2bd-f20ea0ffff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, geojson\n",
    "import random, scipy\n",
    "from collections import defaultdict\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, shape\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import shapely\n",
    "from shapely.ops import transform\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "from terracatalogueclient import Catalogue as Terracat\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8677483-8999-4d3b-8260-f23282eda01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900da101-e53b-4654-ae29-947267be8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056b5d7a-3f85-4ab8-a35c-8e321092772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = 'BIO-4-plant-species.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a8b57-2583-4aa6-8490-f885ad739d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = 'https://api.gbif.org/v1/occurrence/search/'\n",
    "DATASETKEY = '50c9509d-22c7-4a22-a47d-8c48425ef4a7'  # iNaturalist research-grade observations\n",
    "#TAXONKEYS = {'Arthropoda': '54', 'Aves': '212', 'Tracheophyta': '7707728'}\n",
    "TAXON = 'Tracheophyta'\n",
    "TAXON_KEY = '7707728'\n",
    "STARTYEAR = '2016'\n",
    "ENDYEAR = '2021'\n",
    "LIMIT = 300\n",
    "\n",
    "NUM_CURVEFITS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd009f3-7a39-42e9-bd3f-9ef396e0472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-indicators'\n",
    "aws_s3_dir = \"https://\"+bucket_name+\".s3.eu-west-3.amazonaws.com\"\n",
    "boundary_ext = '/data/boundaries/'\n",
    "indicators_file_aws = 'indicators/indicators.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667abf1c-7d80-4afa-9b61-37419706b6b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get list of cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir + boundary_ext + 'boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6946dc-b73c-44b9-80cc-562d0db945c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundingbox_wkt(p):\n",
    "    # Returns WKT for bounding box.\n",
    "    # Necessary because GBIF API won't accept complex polygons.\n",
    "    minx, miny, maxx, maxy = p.bounds\n",
    "    return 'POLYGON (({0} {3}, {0} {2}, {1} {2}, {0} {3}))'.format(str(minx), str(maxx), str(miny), str(maxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573580c6-e545-49df-9d8c-f27d3599f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(poly):\n",
    "    outputs = []\n",
    "    # Get observation records from GBIF\n",
    "    \n",
    "    observations = []\n",
    "    \n",
    "    if poly.type == 'MultiPolygon':\n",
    "        poly = unary_union(poly)\n",
    "    \n",
    "    if str(poly) != 'GEOMETRYCOLLECTION EMPTY':\n",
    "        box = boundingbox_wkt(poly)\n",
    "\n",
    "        offset = -LIMIT\n",
    "        while offset == -LIMIT or not results['endOfRecords']:\n",
    "            offset += LIMIT\n",
    "            url = '{0}?dataset_key={1}&taxon_key={2}&year={3},{4}&geometry={5}&limit={6}&offset={7}&hasCoordinate=true'.format(API_URL, DATASETKEY, TAXON_KEY, STARTYEAR, ENDYEAR, box, LIMIT, offset)\n",
    "            resp = requests.get(url)\n",
    "            results = resp.json()\n",
    "            print('  {0}: {1}/{2}'.format(TAXON, results['offset'], results['count']))\n",
    "            # Note spatial subsetting of points happens below (twice) as part of the conditions in the list comprehensions\n",
    "            observations += [{\n",
    "                'species': i['species'],\n",
    "                'lat': i['decimalLatitude'],  # We don't really need to save lat/lon for this\n",
    "                'lon': i['decimalLongitude'],\n",
    "            } for i in results['results'] if 'species' in i.keys() and Point(float(i['decimalLongitude']), float(i['decimalLatitude'])).within(poly)]\n",
    "        # Estimate species counts by estimating asymptote of species-accumulation curve created when observation order is randomized\n",
    "        # Final estimate is average over NUM_CURVEFITS estimates\n",
    "\n",
    "        #count_estimate = None\n",
    "        if len(observations) > 1:\n",
    "            taxon_observations = [i['species'] for i in observations]\n",
    "            asymptotes = []\n",
    "            tries = 0\n",
    "            while len(asymptotes) < NUM_CURVEFITS:   # Different observation-orders give different results, so average over many\n",
    "                tries += 1\n",
    "                taxon_observations.sort(key=lambda x: random.random())                    # Randomize order of observations\n",
    "                sac = []                                                            # Initialize species accumulation curve data\n",
    "                for obs_count in range(1, len(taxon_observations)):                       # Go through observation list from beginning\n",
    "                    sac.append(len(set(taxon_observations[:obs_count])))                  # and count unique species from start to index\n",
    "                if len(sac) > 5 and tries <= 1000:          # Avoid letting infinite-species errors stop the process\n",
    "                    try:\n",
    "                        asymptotes.append(scipy.optimize.curve_fit(lambda x,a,b,c: -((a*np.exp(-b*x))+c), list(range(1, len(sac)+1)), sac)[0][2])\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    asymptotes.append(-1)\n",
    "            if -1 in asymptotes:\n",
    "                count_estimate = -9999\n",
    "            else:\n",
    "                count_estimate = -round(np.mean(asymptotes))\n",
    "            return count_estimate\n",
    "    return -9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb88e40-da2a-4403-b1a2-ad7412ef2b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_geom(row):\n",
    "    poly = row[0]\n",
    "    if poly.type == 'Polygon':\n",
    "        poly = MultiPolygon([poly])\n",
    "\n",
    "    \n",
    "    taxoncount = get_count(poly)\n",
    "    return taxoncount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3af511-c436-450f-8040-a644b373153d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(boundary_georef)):\n",
    "    if not OUTPUT_FILENAME in os.listdir('.'):\n",
    "        so_far_df = pd.DataFrame()\n",
    "        so_far_df.to_csv(OUTPUT_FILENAME)\n",
    "        so_far = []\n",
    "    else:\n",
    "        so_far_df = pd.read_csv(OUTPUT_FILENAME)\n",
    "        so_far = [so_far_df.iloc[j]['geo_id'] for j in range(len(so_far_df))]\n",
    "    \n",
    "    most_recent = []\n",
    "    for boundary_name in ['aoi_boundary_name', 'units_boundary_name']:\n",
    "        if type(boundary_georef.loc[i, boundary_name]) != float: # sometimes boundary_id is nan\n",
    "            boundary_id = boundary_georef.loc[i, 'geo_name']+'-' + boundary_georef.loc[i, boundary_name]\n",
    "            if not boundary_id in so_far:\n",
    "                print(boundary_id)\n",
    "                boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id+'.geojson'\n",
    "                boundary_geo = requests.get(boundary_path).json()\n",
    "                temp_gdf = gpd.GeoDataFrame.from_features(boundary_geo)\n",
    "                temp_gdf['BIO_4_numberPlantSpecies'] = temp_gdf.apply(do_one_geom, axis=1)\n",
    "                most_recent.append(temp_gdf.copy())\n",
    "\n",
    "                result = pd.concat([so_far_df] + most_recent, axis=0)\n",
    "                result[['geo_id', 'geo_level', 'geo_name', 'geo_parent_name', 'BIO_4_numberPlantSpecies']].to_csv(OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795f672e-79e3-48b9-ac54-c3363cfdda5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedcities = pd.read_csv(OUTPUT_FILENAME)\n",
    "processedcities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aba90c-3abc-4533-beda-21a1747d2f50",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebe850-8281-4c55-a9b2-be3e989131a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table\n",
    "cities_indicators = pd.read_csv(aws_s3_dir +'/'+ indicators_file_aws)\n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8757ef-827e-41b7-b4a9-f1fe73571058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cdef59-dd59-420b-b067-b17373a50c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = processedcities,\n",
    "                                            indicator_name = 'BIO_4_numberPlantSpecies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f88196c-97dc-43e7-ac7a-885d7cf16ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cee1f3-165e-4e88-b002-b1daa8cdce1b",
   "metadata": {},
   "source": [
    "## Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d73d504-1759-4987-b5e6-083b82acdcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978440fa-f020-4b31-9b62-e77307e41ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = indicators_file_aws\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b535ae5-0dda-4ef0-be80-38f08c67cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
