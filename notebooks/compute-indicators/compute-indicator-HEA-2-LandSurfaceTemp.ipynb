{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a66a1-a3b7-4aee-98ab-2b826a1b6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap\n",
    "# !{sys.executable} -m pip install pip rasterstats \n",
    "# # !{sys.executable} -m pip install pip nodejs==0.1.1\n",
    "# # !{sys.executable} -m pip install pip nodejs-bin\n",
    "# # !{sys.executable} -m winget install OpenJS.NodeJS\n",
    "# # !{sys.executable} -m pip install pip oeel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f259e-62a6-4b7e-b879-8628b18a8741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73901903-5245-4507-950b-3a78b2e820b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff69f1a8-e7fa-40ac-81db-f9a67f1e82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import boto3\n",
    "import geopandas as gpd\n",
    "import io\n",
    "# from rasterstats import zonal_stats\n",
    "import fiona\n",
    "import rasterio.mask\n",
    "import geemap\n",
    "import glob\n",
    "import boto3\n",
    "# import nodejs\n",
    "# import oeel\n",
    "# geemap.ee_initialize()\n",
    "# from oeel import oeel\n",
    "# oeel = geemap.requireJS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de7d4d-ed34-493b-8573-ab00825ca668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ea530a-3c18-423a-a28a-de82cfa137ff",
   "metadata": {},
   "source": [
    "# Read input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330baf82-21ca-423c-803a-37782d5d7357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-indicators'\n",
    "aws_s3_dir = \"https://\"+bucket_name+\".s3.eu-west-3.amazonaws.com\"\n",
    "boundary_ext = '/data/boundaries/'\n",
    "indicators_file_aws = 'indicators/indicators.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608e532-fe97-42bc-979e-545e2c748446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for hottest day search ranges\n",
    "\n",
    "start_date = '2013-03-18' # start date of Landsat archive to include in hottest day search\n",
    "end_date = '2022-09-17' # end date of Landsat archive to include in hottest day search\n",
    "start_dateYearStr = str(ee.Date(start_date).get('year').getInfo())\n",
    "end_dateYearStr = str(ee.Date(end_date).get('year').getInfo())\n",
    "window = 90 # number of days to include in LST mean mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66600a-4238-4bb0-a3f8-70195746ffd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Add Land use land cover dataset\n",
    "WC = ee.ImageCollection(\"ESA/WorldCover/v100\")\n",
    "WorldCover = WC.first();\n",
    "builtup = WorldCover.eq(50)\n",
    "\n",
    "## define projection for use later\n",
    "WCprojection = WC.first().projection();  \n",
    "esaScale = WorldCover.projection().nominalScale();  \n",
    "\n",
    "print('WorldCover projection:', WCprojection.getInfo());\n",
    "\n",
    "# Map.addLayer(WorldCover, {'bands': \"Map\"}, \"WorldCover 10m 2020 (ESA)\",1);\n",
    "\n",
    "# Map.add_legend(builtin_legend='ESA_WorldCover',position='bottomleft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358207c4-519b-4ac1-9658-aa4346c29eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add intra-urban land use dataset\n",
    "\n",
    "ULU = ee.ImageCollection(\"projects/wri-datalab/urban_land_use/V1\")\n",
    "\n",
    "WRIulu = ULU.select('lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIulu = WRIulu.mask(WRIulu.mask().gt(0))\n",
    "WRIroad = ULU.select('road_lulc').reduce(ee.Reducer.firstNonNull()).rename('lulc')\n",
    "WRIuluwRoad = WRIulu.add(WRIroad).where(WRIroad.eq(1),6).mask(WRIulu.mask().gt(0))\n",
    "\n",
    "ULUmaskedESA = WRIuluwRoad.updateMask(WorldCover.eq(50)) #.Or(WorldCover.eq(60)))\n",
    "\n",
    "ULUmaskedESA = ULUmaskedESA.reproject(\n",
    "      crs= WCprojection\n",
    "    )\n",
    "\n",
    "CLASSES_7=[\n",
    "  \"open_space\",\n",
    "  \"nonresidential\",\n",
    "  \"atomistic\",\n",
    "  \"informal_subdivision\",\n",
    "  \"formal_subdivision\",\n",
    "  \"housing_project\",\n",
    "  \"road\"]\n",
    "COLORS_7=[\n",
    "  '33A02C',\n",
    "  'E31A1C',\n",
    "  'FB9A99',\n",
    "  'FFFF99',\n",
    "  '1F78B4',\n",
    "  'A6CEE3',\n",
    "  '3f3f3f']  \n",
    "ULU7Params = {\"bands\": ['lulc'], 'min': 0, 'max': 6, \"opacity\": 1, \"palette\": COLORS_7}\n",
    "\n",
    "#Map.addLayer(ULUmaskedESA,ULU7Params,\"Urban Land Use 2020 (WRI) masked to WorldCover built\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17463af5-15ee-4c33-8015-00f2875d0b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  METHODS TO CALCULATE MEAN LST MOSAIC FOR HOTTEST PERIOD USING LANDSAT\n",
    "\n",
    "\"\"\"\"\n",
    "Derived from\n",
    "LSTfun = require('users/sofiaermida/landsat_smw_lst:modules/SMWalgorithm.js')\n",
    "'Author': Sofia Ermida (sofia.ermida@ipma.pt; @ermida_sofia)\n",
    "\n",
    "This code is free and open.\n",
    "By using this code and any data derived with it,\n",
    "you agree to cite the following reference\n",
    "'in any publications derived from them':\n",
    "Ermida, S.L., Soares, P., Mantas, V., GÃ¶ttsche, F.-M., Trigo, I.F., 2020.\n",
    "    Google Earth Engine open-source code for Land Surface Temperature estimation from the Landsat series.\n",
    "    'Remote Sensing, 12 (9), 1471; https://doi.org/10.3390/rs12091471\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#LandsatLST = require('users/emackres/DataPortal:/Landsat_LST.js')\n",
    "#cloudmask = require('users/emackres/DataPortal:/cloudmask.js')\n",
    "\n",
    "COLLECTION = ee.Dictionary({\n",
    "  'L4': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LT04/C02/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LT04/C02/T1_L2'),\n",
    "    'TIR': ['B6',],\n",
    "    'VISW': ['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B7','QA_PIXEL']\n",
    "  },\n",
    "  'L5': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LT05/C02/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LT05/C02/T1_L2'),\n",
    "    'TIR': ['B6',],\n",
    "    'VISW': ['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B7','QA_PIXEL']\n",
    "  },\n",
    "  'L7': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LE07/C02/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LE07/C02/T1_L2'),\n",
    "    'TIR': ['B6_VCID_1','B6_VCID_2'],\n",
    "    'VISW': ['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B7','QA_PIXEL']\n",
    "  },\n",
    "  'L8': {\n",
    "    'TOA': ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA'),\n",
    "    'SR': ee.ImageCollection('LANDSAT/LC08/C02/T1_L2'),\n",
    "    'TIR': ['B10','B11'],\n",
    "    'VISW': ['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7','QA_PIXEL']\n",
    "  }\n",
    "});\n",
    "\n",
    "\n",
    "def NDVIaddBand(landsat):\n",
    "  def wrap(image):\n",
    "\n",
    "    # choose bands\n",
    "    nir = ee.String(ee.Algorithms.If(landsat=='L8','SR_B5','SR_B4'))\n",
    "    red = ee.String(ee.Algorithms.If(landsat=='L8','SR_B4','SR_B3'))\n",
    "  \n",
    "    # compute NDVI \n",
    "    return image.addBands(image.expression('(nir-red)/(nir+red)',{\n",
    "      'nir':image.select(nir).multiply(0.0000275).add(-0.2),\n",
    "      'red':image.select(red).multiply(0.0000275).add(-0.2)\n",
    "    }).rename('NDVI'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def FVCaddBand(landsat):\n",
    "  def wrap(image):\n",
    "\n",
    "    ndvi = image.select('NDVI')\n",
    "\n",
    "    # Compute FVC\n",
    "    fvc = image.expression('((ndvi-ndvi_bg)/(ndvi_vg - ndvi_bg))**2',\n",
    "      {'ndvi':ndvi,'ndvi_bg':0.2,'ndvi_vg':0.86})\n",
    "    fvc = fvc.where(fvc.lt(0.0),0.0)\n",
    "    fvc = fvc.where(fvc.gt(1.0),1.0)\n",
    "\n",
    "    return image.addBands(fvc.rename('FVC'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def NCEP_TPWaddBand(image):\n",
    "\n",
    "  # first select the day of interest\n",
    "  date = ee.Date(image.get('system:time_start'))\n",
    "  year = ee.Number.parse(date.format('yyyy'))\n",
    "  month = ee.Number.parse(date.format('MM'))\n",
    "  day = ee.Number.parse(date.format('dd'))\n",
    "  date1 = ee.Date.fromYMD(year,month,day)\n",
    "  date2 = date1.advance(1,'days')\n",
    "\n",
    "  # function compute the time difference from landsat image\n",
    "  def datedist(image):\n",
    "    return image.set('DateDist',\n",
    "      ee.Number(image.get('system:time_start')) \\\n",
    "      .subtract(date.millis()).abs())\n",
    "  \n",
    "\n",
    "  # load atmospheric data collection\n",
    "  TPWcollection = ee.ImageCollection('NCEP_RE/surface_wv') \\\n",
    "                  .filter(ee.Filter.date(date1.format('yyyy-MM-dd'), date2.format('yyyy-MM-dd'))) \\\n",
    "                  .map(datedist)\n",
    "\n",
    "  # select the two closest model times\n",
    "  closest = (TPWcollection.sort('DateDist')).toList(2)\n",
    "\n",
    "  # check if there is atmospheric data in the wanted day\n",
    "  # if not creates a TPW image with non-realistic values\n",
    "  # these are then masked in the SMWalgorithm function (prevents errors)\n",
    "  tpw1 = ee.Image(ee.Algorithms.If(closest.size().eq(0), ee.Image.constant(-999.0),\n",
    "                      ee.Image(closest.get(0)).select('pr_wtr') ))\n",
    "  tpw2 = ee.Image(ee.Algorithms.If(closest.size().eq(0), ee.Image.constant(-999.0),\n",
    "                        ee.Algorithms.If(closest.size().eq(1), tpw1,\n",
    "                        ee.Image(closest.get(1)).select('pr_wtr') )))\n",
    "\n",
    "  time1 = ee.Number(ee.Algorithms.If(closest.size().eq(0), 1.0,\n",
    "                        ee.Number(tpw1.get('DateDist')).divide(ee.Number(21600000)) ))\n",
    "  time2 = ee.Number(ee.Algorithms.If(closest.size().lt(2), 0.0,\n",
    "                        ee.Number(tpw2.get('DateDist')).divide(ee.Number(21600000)) ))\n",
    "\n",
    "  tpw = tpw1.expression('tpw1*time2+tpw2*time1',\n",
    "                            {'tpw1':tpw1,\n",
    "                            'time1':time1,\n",
    "                            'tpw2':tpw2,\n",
    "                            'time2':time2\n",
    "                            }).clip(image.geometry())\n",
    "\n",
    "  # SMW coefficients are binned by TPW values\n",
    "  # find the bin of each TPW value\n",
    "  pos = tpw.expression(\n",
    "    \"value = (TPW>0 && TPW<=6) ? 0\" + \\\n",
    "    \": (TPW>6 && TPW<=12) ? 1\" + \\\n",
    "    \": (TPW>12 && TPW<=18) ? 2\" + \\\n",
    "    \": (TPW>18 && TPW<=24) ? 3\" + \\\n",
    "    \": (TPW>24 && TPW<=30) ? 4\" + \\\n",
    "    \": (TPW>30 && TPW<=36) ? 5\" + \\\n",
    "    \": (TPW>36 && TPW<=42) ? 6\" + \\\n",
    "    \": (TPW>42 && TPW<=48) ? 7\" + \\\n",
    "    \": (TPW>48 && TPW<=54) ? 8\" + \\\n",
    "    \": (TPW>54) ? 9\" + \\\n",
    "    \": 0\",{'TPW': tpw}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "  # add tpw to image as a band\n",
    "  withTPW = (image.addBands(tpw.rename('TPW'),['TPW'])).addBands(pos.rename('TPWpos'),['TPWpos'])\n",
    "\n",
    "  return withTPW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# get ASTER emissivity\n",
    "aster = ee.Image(\"NASA/ASTER_GED/AG100_003\")\n",
    "\n",
    "#get ASTER FVC from NDVI\n",
    "aster_ndvi = aster.select('ndvi').multiply(0.01)\n",
    "\n",
    "aster_fvc = aster_ndvi.expression('((ndvi-ndvi_bg)/(ndvi_vg - ndvi_bg))**2',\n",
    "  {'ndvi':aster_ndvi,'ndvi_bg':0.2,'ndvi_vg':0.86})\n",
    "aster_fvc = aster_fvc.where(aster_fvc.lt(0.0),0.0)\n",
    "aster_fvc = aster_fvc.where(aster_fvc.gt(1.0),1.0)\n",
    "\n",
    "# bare ground emissivity functions for each band\n",
    "def ASTERGEDemiss_bare_band10(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band10').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band11(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band11').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band12(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band12').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band13(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band13').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def ASTERGEDemiss_bare_band14(image):\n",
    "  return image.expression('(EM - 0.99*fvc)/(1.0-fvc)',{\n",
    "    'EM':aster.select('emissivity_band14').multiply(0.001),\n",
    "    'fvc':aster_fvc}) \\\n",
    "    .clip(image.geometry())\n",
    "\n",
    "\n",
    "def EMaddBand(landsat, use_ndvi):\n",
    "  def wrap(image):\n",
    "\n",
    "    c13 = ee.Number(ee.Algorithms.If(landsat == 'L4',0.3222,\n",
    "                            ee.Algorithms.If(landsat == 'L5',-0.0723,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.2147,\n",
    "                            0.6820))))\n",
    "    c14 = ee.Number(ee.Algorithms.If(landsat == 'L4',0.6498,\n",
    "                            ee.Algorithms.If(landsat == 'L5',1.0521,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.7789,\n",
    "                            0.2578))))\n",
    "    c = ee.Number(ee.Algorithms.If(landsat == 'L4',0.0272,\n",
    "                            ee.Algorithms.If(landsat == 'L5',0.0195,\n",
    "                            ee.Algorithms.If(landsat == 'L7',0.0059,\n",
    "                            0.0584))))\n",
    "\n",
    "    # get ASTER emissivity\n",
    "    # convolve to Landsat band\n",
    "    emiss_bare = image.expression('c13*EM13 + c14*EM14 + c',{\n",
    "      'EM13':ASTERGEDemiss_bare_band13(image),\n",
    "      'EM14':ASTERGEDemiss_bare_band14(image),\n",
    "      'c13':ee.Image(c13),\n",
    "      'c14':ee.Image(c14),\n",
    "      'c':ee.Image(c)\n",
    "      })\n",
    "\n",
    "    # compute the dynamic emissivity for Landsat\n",
    "    EMd = image.expression('fvc*0.99+(1-fvc)*em_bare',\n",
    "      {'fvc':image.select('FVC'),'em_bare':emiss_bare})\n",
    "\n",
    "    # compute emissivity directly from ASTER\n",
    "    # without vegetation correction\n",
    "    # get ASTER emissivity\n",
    "    aster = ee.Image(\"NASA/ASTER_GED/AG100_003\") \\\n",
    "      .clip(image.geometry())\n",
    "    EM0 = image.expression('c13*EM13 + c14*EM14 + c',{\n",
    "      'EM13':aster.select('emissivity_band13').multiply(0.001),\n",
    "      'EM14':aster.select('emissivity_band14').multiply(0.001),\n",
    "      'c13':ee.Image(c13),\n",
    "      'c14':ee.Image(c14),\n",
    "      'c':ee.Image(c)\n",
    "      })\n",
    "\n",
    "    # select which emissivity to output based on user selection\n",
    "    EM = ee.Image(ee.Algorithms.If(use_ndvi,EMd,EM0))\n",
    "\n",
    "    return image.addBands(EM.rename('EM'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "def get_lookup_table(fc, prop_1, prop_2):\n",
    "  reducer = ee.Reducer.toList().repeat(2)\n",
    "  lookup = fc.reduceColumns(reducer, [prop_1, prop_2])\n",
    "  return ee.List(lookup.get('list'))\n",
    "\n",
    "def LSTaddBand(landsat):\n",
    "  \n",
    "  def wrap(image):\n",
    "  \n",
    "    # coefficients for the Statistical Mono-Window Algorithm\n",
    "    coeff_SMW_L8 = ee.FeatureCollection([\n",
    "      ee.Feature(None, {'TPWpos': 0, 'A': 0.9751, 'B': -205.8929, 'C': 212.7173}),\n",
    "      ee.Feature(None, {'TPWpos': 1, 'A': 1.0090, 'B': -232.2750, 'C': 230.5698}),\n",
    "      ee.Feature(None, {'TPWpos': 2, 'A': 1.0541, 'B': -253.1943, 'C': 238.9548}),\n",
    "      ee.Feature(None, {'TPWpos': 3, 'A': 1.1282, 'B': -279.4212, 'C': 244.0772}),\n",
    "      ee.Feature(None, {'TPWpos': 4, 'A': 1.1987, 'B': -307.4497, 'C': 251.8341}),\n",
    "      ee.Feature(None, {'TPWpos': 5, 'A': 1.3205, 'B': -348.0228, 'C': 257.2740}),\n",
    "      ee.Feature(None, {'TPWpos': 6, 'A': 1.4540, 'B': -393.1718, 'C': 263.5599}),\n",
    "      ee.Feature(None, {'TPWpos': 7, 'A': 1.6350, 'B': -451.0790, 'C': 268.9405}),\n",
    "      ee.Feature(None, {'TPWpos': 8, 'A': 1.5468, 'B': -429.5095, 'C': 275.0895}),\n",
    "      ee.Feature(None, {'TPWpos': 9, 'A': 1.9403, 'B': -547.2681, 'C': 277.9953})\n",
    "    ]);\n",
    "    # Select algorithm coefficients\n",
    "    coeff_SMW = ee.FeatureCollection(coeff_SMW_L8)\n",
    "\n",
    "    # Create lookups for the algorithm coefficients\n",
    "    A_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'A');\n",
    "    B_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'B');\n",
    "    C_lookup = get_lookup_table(coeff_SMW, 'TPWpos', 'C');\n",
    "  \n",
    "    # Map coefficients to the image using the TPW bin position\n",
    "    A_img = image.remap(A_lookup.get(0), A_lookup.get(1),0.0,'TPWpos').resample('bilinear');\n",
    "    B_img = image.remap(B_lookup.get(0), B_lookup.get(1),0.0,'TPWpos').resample('bilinear');\n",
    "    C_img = image.remap(C_lookup.get(0), C_lookup.get(1),0.0,'TPWpos').resample('bilinear');\n",
    "    \n",
    "    # select TIR band\n",
    "    tir = ee.String(ee.Algorithms.If(landsat=='L8','B10',\n",
    "                        ee.Algorithms.If(landsat=='L7','B6_VCID_1',\n",
    "                        'B6')));\n",
    "    # compute the LST\n",
    "    lst = image.expression(\n",
    "      'A*Tb1/em1 + B/em1 + C',\n",
    "         {'A': A_img,\n",
    "          'B': B_img,\n",
    "          'C': C_img,\n",
    "          'em1': image.select('EM'),\n",
    "          'Tb1': image.select(tir)\n",
    "         }).updateMask(image.select('TPW').lt(0).Not());\n",
    "         \n",
    "    return image.addBands(lst.rename('LST'))\n",
    "\n",
    "  return wrap\n",
    "\n",
    "\n",
    "# cloudmask for TOA data\n",
    "def cloudmasktoa(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 3)\n",
    "  return image.updateMask(mask.Not())\n",
    "\n",
    "\n",
    "# cloudmask for SR data\n",
    "def cloudmasksr(image):\n",
    "  qa = image.select('QA_PIXEL')\n",
    "  mask = qa.bitwiseAnd(1 << 3) \\\n",
    "    .Or(qa.bitwiseAnd(1 << 4))\n",
    "  return image.updateMask(mask.Not())\n",
    "\n",
    "\n",
    "def LSTcollection(landsat, date_start, date_end, geometry, image_limit, use_ndvi):\n",
    "\n",
    "  # load TOA Radiance/Reflectance\n",
    "  collection_dict = ee.Dictionary(COLLECTION.get(landsat))\n",
    "\n",
    "  landsatTOA = ee.ImageCollection(collection_dict.get('TOA')) \\\n",
    "                .filter(ee.Filter.date(date_start, date_end)) \\\n",
    "                .filterBounds(geometry) \\\n",
    "                .map(cloudmasktoa)\n",
    "                #.limit(image_limit,'CLOUD_COVER_LAND') \\\n",
    "    \n",
    "  # load Surface Reflectance collection for NDVI\n",
    "  landsatSR = ee.ImageCollection(collection_dict.get('SR')) \\\n",
    "                .filter(ee.Filter.date(date_start, date_end)) \\\n",
    "                .filterBounds(geometry) \\\n",
    "                .map(cloudmasksr) \\\n",
    "                .map(NDVIaddBand(landsat)) \\\n",
    "                .map(FVCaddBand(landsat)) \\\n",
    "                .map(NCEP_TPWaddBand) \\\n",
    "                .map(EMaddBand(landsat,use_ndvi))\n",
    "                #.limit(image_limit,'CLOUD_COVER_LAND') \\\n",
    "\n",
    "# combine collections\n",
    "# all channels from surface reflectance collection\n",
    "# except tir channels: from TOA collection\n",
    "# select TIR bands\n",
    "  tir = ee.List(collection_dict.get('TIR'));\n",
    "  visw = (ee.List(collection_dict.get('VISW'))\n",
    "    .add('NDVI')\n",
    "    .add('FVC')\n",
    "    .add('TPW')\n",
    "    .add('TPWpos')\n",
    "    .add('EM')\n",
    "         )\n",
    "  landsatALL = (landsatSR.select(visw).combine(landsatTOA.select(tir), True));\n",
    "  \n",
    "  # compute the LST\n",
    "  landsatLST = landsatALL.map(LSTaddBand(landsat));\n",
    "\n",
    "  return landsatLST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38ae89-a96b-4bd3-9387-8b07baa9ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HottestPeriod(FC,start_date,end_date):\n",
    "    FCcenter = FC.geometry().centroid(10)\n",
    "    #  CALCULATE DATES OF HOTTEST PERIOD OF HIGH TEMPERATURES FOR EACH PIXEL\n",
    "\n",
    "    # select dataset, filter by dates and visualize\n",
    "    # dataset = (ee.ImageCollection('NASA/NEX-GDDP')\n",
    "    #            .filter(ee.Filter.And(\n",
    "    #                ee.Filter.date(start_date, end_date),\n",
    "    #                ee.Filter.eq('scenario','rcp85'),\n",
    "    #                 ee.Filter.eq('model','BNU-ESM'),\n",
    "    #                ee.Filter.bounds(FC)\n",
    "    #            ))\n",
    "    #           )\n",
    "    # AirTemperature = dataset.select(['tasmax'])\n",
    "    dataset = ee.ImageCollection(\"ECMWF/ERA5/DAILY\")\n",
    "    AirTemperature = (dataset\n",
    "                      .filter(ee.Filter.And(\n",
    "                        ee.Filter.date(start_date, end_date),\n",
    "                        ee.Filter.bounds(FC)))\n",
    "                      .select(['maximum_2m_air_temperature'],['tasmax'])\n",
    "                             )\n",
    "    AirTemperatureVis = {\n",
    "      'min': 240.0,\n",
    "      'max': 300.0,\n",
    "      'palette': ['blue', 'purple', 'cyan', 'green', 'yellow', 'red'],\n",
    "    }\n",
    "    #Map.addLayer(AirTemperature, AirTemperatureVis, 'Max Air Temperature')\n",
    "    #print(AirTemperature)\n",
    "\n",
    "    # add date as a band to image collection\n",
    "    def addDate(image):\n",
    "        img_date = ee.Date(image.date())\n",
    "        img_date = ee.Number.parse(img_date.format('YYYYMMdd'))\n",
    "        return image.addBands(ee.Image(img_date).rename('date').toInt())\n",
    "\n",
    "    withdates = AirTemperature.map(addDate)\n",
    "    #print(withdates)\n",
    "\n",
    "    # create a composite with the hottest day value and dates for every location and add to map\n",
    "    hottest = withdates.qualityMosaic('tasmax')\n",
    "    #print(hottest)\n",
    "    #Map.addLayer(hottest.select('tasmax'), AirTemperatureVis, 'Max temp',0)\n",
    "\n",
    "    # reduce composite to get the hottest date for centroid of ROI\n",
    "    resolution = dataset.first().projection().nominalScale()\n",
    "    NEXtempMax = str(ee.Number(hottest.reduceRegion(ee.Reducer.firstNonNull(), FCcenter, resolution).get('date')).getInfo())\n",
    "    #print(NEXtempMax.getInfo())\n",
    "\n",
    "    # convert date number to date type\n",
    "    date = ee.Date.parse('YYYYMMdd',NEXtempMax)\n",
    "    #print(date.getInfo())\n",
    "    \n",
    "    # calculate relative start and end dates\n",
    "    startwindowadvance = ee.Number(window).multiply(-0.5).add(1)\n",
    "    endwindowadvance = ee.Number(window).multiply(0.5)\n",
    "\n",
    "    # calculate 45 days before and after hottest date.  Format as short date.\n",
    "    startwindowdate = date.advance(startwindowadvance, 'day').format('YYYY-MM-dd')\n",
    "    endwindowdate = date.advance(endwindowadvance, 'day').format('YYYY-MM-dd')\n",
    "    return date, startwindowdate, endwindowdate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2d87ec-3ae7-4d84-8621-95c2b5dcd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LST(FC,hottestdate,start,end):\n",
    "    # select parameters: date range, and landsat satellite\n",
    "    landsat = 'L8' # options: 'L4', 'L5', 'L7', 'L8'\n",
    "    use_ndvi = False\n",
    "    date_start = start_date # start for beginning of hottest window or custom date in format '2020-12-20' or start_date for whole achive\n",
    "    date_end = end_date # end for end of hottest window or custom date in format '2020-12-20' or end_date for whole achive\n",
    "    image_limit = 100\n",
    "    month = hottestdate.get('month')\n",
    "    month_start = month #month.subtract(1) # 1 # or month\n",
    "    month_end = month #month.add(1) # 12 # or month\n",
    "\n",
    "    \n",
    "    # get landsat collection with added variables: NDVI, FVC, TPW, EM, LST\n",
    "    # link to the code that computes the Landsat LST\n",
    "    # oeel = geemap.requireJS()\n",
    "    # Landsat_LST = geemap.requireJS('users/emackres/DataPortal:Landsat_LST.js')\n",
    "    # LandsatColl = Landsat_LST.collection(landsat, date_start, date_end, FC, image_limit, use_ndvi).filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "    LandsatColl = LSTcollection(landsat, date_start, date_end, FC, image_limit, use_ndvi).filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "    LSTmean = LandsatColl.select('LST').reduce(ee.Reducer.mean()).subtract(273.15)\n",
    "    return LSTmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505ca1d-01e6-45a3-b938-c75750a522ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HighLST(FC,LSTmean):    \n",
    "    # define \"high LST\" threshold\n",
    "    UrbanLSTmean = LSTmean.updateMask(builtup)\n",
    "    UrbanAreaLSTReduction = UrbanLSTmean.reduceRegion(ee.Reducer.mean(),FC,100) # default scale: 100 can increase if \"User memory limit exceeded\". # or ee.Reducer.percentile([50]) for median LST of region\n",
    "    thesholdAdder = 3 # degrees C above UrbanAreaReduction value at which to set threshold\n",
    "    TempThresValue = ee.Number(UrbanAreaLSTReduction.get('LST_mean')).multiply(100).round().divide(100).add(thesholdAdder).getInfo()\n",
    "    LSTmeanThres = LSTmean.updateMask(LSTmean.gte(TempThresValue))#.eq(1).toByte()\n",
    "    return LSTmeanThres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa5ee9-8643-433d-9275-0fbc3ba0230b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir + boundary_ext + 'boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43863d6-03d2-48fd-9abb-5fd16e528e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create test map\n",
    "# for i in range(12,13):#,len(boundary_georef)): #9,10):# for Mexico City\n",
    "#     print(i)\n",
    "#     geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "#     print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "#     boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "#     boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "\n",
    "#     # process aoi level ------\n",
    "#     print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "#     # read boundaries\n",
    "#     boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id_aoi+'.geojson'\n",
    "#     boundary_geo = requests.get(boundary_path).json()\n",
    "#     boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "#     FC = boundary_geo_ee\n",
    "#     # obtain LST for location, time and threshold\n",
    "#     hottestdate, start, end = HottestPeriod(FC,start_date,end_date)\n",
    "#     # print(\"\\n hottest date: \",hottestdate)\n",
    "#     LSTmean = LST(FC, hottestdate, start, end)\n",
    "#     LSTmeanThres = HighLST(FC,LSTmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23f3fc-2804-4520-8c8b-ed082c33a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display test map\n",
    "# ## create map\n",
    "# Map = geemap.Map(height=\"350px\")\n",
    "# Map.add_basemap('HYBRID');\n",
    "# Map.centerObject(FC,12)\n",
    "# Map.addLayer(LSTmeanThres,{'min':20, 'max':45, 'palette':['blue', 'cyan', 'green', 'yellow', 'red']}, 'Mean land surface temperature C')\n",
    "# Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e1c571-5f1e-4a24-8dd7-9222ffe1097a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627571f8-42ce-4aaf-b8fa-cea8770d6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define calcuation function to get pixel counts, convert to percents and append to data frame\n",
    "def CountCalcsDF(FC,LSTmeanThres,DF):\n",
    "        \n",
    "    # # obtain LST for location, time and threshold\n",
    "    # hottestdate, start, end = HottestPeriod(FC,start_date,end_date)\n",
    "    # LSTmean = LST(FC, hottestdate, start, end)\n",
    "    # LSTmeanThres = HighLST(FC,LSTmean)\n",
    "    \n",
    "    # startStr = str(start.getInfo())\n",
    "    # endStr = str(end.getInfo())\n",
    "    # monthStr = str(hottestdate.get('month').getInfo())\n",
    "    # byPeriod = '-'+startStr+'to'+endStr+''\n",
    "    # byMonth = '-month'+monthStr+'for'+start_dateYearStr+'to'+end_dateYearStr+''\n",
    "    byMonthShort = '-'+start_dateYearStr+'to'+end_dateYearStr+'meanofmonthwhottestday'\n",
    "    mosaicmethod = byMonthShort\n",
    "    \n",
    "    # reduce images to get vegetation and built-up pixel counts\n",
    "    pixelcounts = LSTmeanThres.reduceRegions(FC,ee.Reducer.count().setOutputs(['HotBuiltPixels']),100)#esaScale) # larger scale (50+) required for large cities to avoid EE memory issues\n",
    "    pixelcounts = builtup.reduceRegions(pixelcounts,ee.Reducer.count().setOutputs(['BuiltPixels']),100)#esaScale) # larger scale (50+) required for large cities to avoid EE memory issues\n",
    "\n",
    "    # convert pixel counts to area percentages and saves to FC as property\n",
    "    def toPct(feat):\n",
    "        pct = (feat.getNumber('HotBuiltPixels')).divide(feat.getNumber('BuiltPixels'))\n",
    "        return feat.set({\n",
    "            'PctHighLSTBuilt'+mosaicmethod+'': pct\n",
    "      })\n",
    "\n",
    "    pixelcounts = pixelcounts.map(toPct).select(['geo_id','PctHighLSTBuilt'+mosaicmethod+''])\n",
    "\n",
    "    # store in df and append\n",
    "    df = geemap.ee_to_pandas(pixelcounts)\n",
    "    df = df.rename(columns={'PctHighLSTBuilt'+mosaicmethod+'': 'HEA_2_percentBuiltupwHighLST'+mosaicmethod+''})\n",
    "    DF = DF.append(df)\n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5654a3cd-1bce-4d0c-8fcf-3ca921481811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use if using EE featurecollections for calculations\n",
    "# define calcuation function to get pixel counts, convert to percents and append to data frame\n",
    "def CountCalcsEEfc(FC,DF):\n",
    "    \n",
    "    # # obtain LST for location, time and threshold\n",
    "    # hottestdate, start, end = HottestPeriod(FC,start_date,end_date)\n",
    "    # LSTmean = LST(FC, hottestdate, start, end)\n",
    "    # LSTmeanThres = HighLST(FC,LSTmean)\n",
    "    \n",
    "    # startStr = str(start.getInfo())\n",
    "    # endStr = str(end.getInfo())\n",
    "    # monthStr = str(hottestdate.get('month').getInfo())\n",
    "    # byPeriod = '-'+startStr+'to'+endStr+''\n",
    "    # byMonth = '-month'+monthStr+'for'+start_dateYearStr+'to'+end_dateYearStr+''\n",
    "    byMonthShort = '-'+start_dateYearStr+'to'+end_dateYearStr+'meanofmonthwhottestday'\n",
    "    mosaicmethod = byMonthShort\n",
    "    \n",
    "    # reduce images to get vegetation and built-up pixel counts\n",
    "    pixelcounts = LSTmeanThres.reduceRegions(FC,ee.Reducer.count().setOutputs(['HotBuiltPixels']),100) #esaScale) \n",
    "    pixelcounts = builtup.reduceRegions(pixelcounts,ee.Reducer.count().setOutputs(['BuiltPixels']),100) #esaScale)\n",
    "\n",
    "    # convert pixel counts to area percentages and saves to FC as property\n",
    "    def toPct(feat):\n",
    "        pct = (feat.getNumber('HotBuiltPixels')).divide(feat.getNumber('BuiltPixels'))\n",
    "        return feat.set({\n",
    "            'PctHighLSTBuilt'+mosaicmethod+'': pct\n",
    "      })\n",
    "\n",
    "    pixelcounts = pixelcounts.map(toPct).select(['geo_id','PctHighLSTBuilt'+mosaicmethod+''])\n",
    "  \n",
    "    # amend existing FeatureCollection with pixel counts for new geographies\n",
    "    DF = ee.FeatureCollection([DF,pixelcounts]).flatten()\n",
    "    return DF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155f1c4-4efe-4b67-916f-29090041d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicatorDF = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24982dcd-14b4-4cd7-bc82-062a9370de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicator = ee.FeatureCollection([])\n",
    "this_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a7e21-e324-45ec-bd84-51e0a682eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(boundary_georef)): #cities not working: 13\n",
    "    print(i)\n",
    "    geo_name = boundary_georef.loc[i, 'geo_name']\n",
    "    print(\"\\n geo_name: \"+geo_name)\n",
    "    \n",
    "    boundary_id_aoi = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'aoi_boundary_name']\n",
    "    boundary_id_unit = boundary_georef.loc[i, 'geo_name']+'-'+boundary_georef.loc[i, 'units_boundary_name']\n",
    "\n",
    "    \n",
    "    # process aoi level ------\n",
    "    print(\"\\n boundary_id_aoi: \"+boundary_id_aoi)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id_aoi+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    \n",
    "    # obtain LST for location, time and threshold\n",
    "    hottestdate, start, end = HottestPeriod(boundary_geo_ee,start_date,end_date)\n",
    "    LSTmean = LST(boundary_geo_ee, hottestdate, start, end)\n",
    "    LSTmeanThres = HighLST(boundary_geo_ee,LSTmean)\n",
    "    \n",
    "    this_indicatorDF = CountCalcsDF(boundary_geo_ee, LSTmeanThres, this_indicatorDF)\n",
    "    # this_indicator = CountCalcsEEfc(boundary_geo_ee,this_indicator) # run this instead if using CountCalcsEE approach\n",
    "    \n",
    "    # process unit of analysis level ------\n",
    "    print(\"\\n boundary_id_unit: \"+boundary_id_unit)\n",
    "    # read boundaries\n",
    "    boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id_unit+'.geojson'\n",
    "    boundary_geo = requests.get(boundary_path).json()\n",
    "    boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "    this_indicatorDF = CountCalcsDF(boundary_geo_ee, LSTmeanThres, this_indicatorDF)\n",
    "    # this_indicator = CountCalcsEEfc(boundary_geo_ee,this_indicator) # run this instead if using CountCalcsEE approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6671f-d6e4-4684-9d08-84f3a635be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_indicatorDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492eef8-d72d-42ab-8631-2f26d5d75b7e",
   "metadata": {},
   "source": [
    "# Workaround for timeout problems for specific geographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889190b-e5a2-47b5-bf7c-a31f9b4c4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # if timeout problems for a geography (and don't want to or have already tried adjusting scale of reductions), use CountCalcsEE and save ee.FeatureCollection as EE asset before coverting to dataframe\n",
    "    task = ee.batch.Export.table.toAsset(\n",
    "        collection = this_indicator, \n",
    "        description = 'thisindicator',\n",
    "        assetId = 'users/emackres/thisindicator',\n",
    "    )\n",
    "\n",
    "    task.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68355b04-1bdd-43d3-8761-330167a0e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    task.status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc9638-ce67-499a-9ad2-d65491cfda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # wait until EE asset is generated (with task state of \"COMPLETED\") before running\n",
    "    # store FC in df and apend to this_indicatorDF\n",
    "\n",
    "    FC = ee.FeatureCollection('users/emackres/thisindicator')\n",
    "    df = geemap.ee_to_pandas(FC)\n",
    "    df = df.rename(columns={'PctHighLSTBuilt'+mosaicmethod+'': 'HEA_2_percentBuiltupwHighLST'+mosaicmethod+''})\n",
    "    this_indicatorDF = this_indicatorDF.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ba28c-f0f3-4a53-8243-cb35476f4d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    this_indicatorDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63a9a9-5bb0-435c-bcfe-499eed1e77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #delete GEE asset \n",
    "    ee.data.deleteAsset('users/emackres/thisindicator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5abd9b-097c-4676-a500-ecd45ad77374",
   "metadata": {},
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fba45-59b3-44fe-94a9-3520763dffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table\n",
    "cities_indicators = pd.read_csv(aws_s3_dir +'/'+ indicators_file_aws)\n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978df631-317b-4c42-8c8a-d8ee108e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        new_indicator_table = new_indicator_table.drop_duplicates()\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left',\n",
    "                                                     validate='one_to_many')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa73a3a-ea72-42ab-81ed-589b95ef33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = this_indicatorDF,\n",
    "                                            indicator_name = 'HEA_2_percentBuiltupwHighLST-'+start_dateYearStr+'to'+end_dateYearStr+'meanofmonthwhottestday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10c1e2-9aa9-4d43-a110-8550e4f36e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba258d2-9e13-4fcc-bf22-4aeb3f359405",
   "metadata": {},
   "source": [
    "# Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059a57-b6a6-4354-b24b-f45102ec8399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2235f8-fb77-40f6-91d8-908dca3fd164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = indicators_file_aws\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ed391-015d-4778-acc5-37c0c7a04703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf202dd-5adf-44d6-83b2-bcba1e8e3d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:notebook] *",
   "language": "python",
   "name": "conda-env-notebook-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
