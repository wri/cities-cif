{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1662b-6b27-4b79-9d8d-7c5c0bd52929",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pip earthengine-api\n",
    "# !{sys.executable} -m pip install pip geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb454f14-522f-450c-b90b-a022f3714fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed0cfe-4d8f-403c-9c06-6bd5982b9ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, geojson, gc\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710633a1-e5be-4a04-b81e-ca852ebd8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9bca6-ce68-4d0e-b125-4828819790dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d9a906-e859-41a3-a8eb-5f6118a79378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory\n",
    "out_dir = os.getcwd()\n",
    "bucket_name = 'cities-indicators'\n",
    "aws_s3_dir = \"https://\"+bucket_name+\".s3.eu-west-3.amazonaws.com\"\n",
    "boundary_ext = '/data/boundaries/'\n",
    "indicators_file_aws = 'indicators/indicators.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee626da-5093-443c-8733-a4924e0ba4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILENAME = 'LND-5-habitat-types-restored.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4136ee-5adf-4363-984d-c32893df7dff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get list of cities\n",
    "boundary_georef = pd.read_csv(aws_s3_dir + boundary_ext + 'boundary_georef.csv')\n",
    "boundary_georef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c511110b-41e9-405e-a770-28289d254fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from GLAD ARD types to simpler habitat types\n",
    "# ARD legend is at https://storage.googleapis.com/earthenginepartners-hansen/GLCLU2000-2020/legend.xlsx\n",
    "LANDCLASSES = {}\n",
    "for j in range(0, 19):\n",
    "    LANDCLASSES[j] = {'name': 'upland sparse vegetation', 'classval': 1, 'is_habitat': False}\n",
    "for j in range(19, 25):\n",
    "    LANDCLASSES[j] = {'name': 'upland short vegetation', 'classval': 2, 'is_habitat': True}\n",
    "for j in range(25, 49):\n",
    "    LANDCLASSES[j] = {'name': 'upland tree cover', 'classval': 3, 'is_habitat': True}\n",
    "for j in range(100, 119):\n",
    "    LANDCLASSES[j] = {'name': 'wetland sparse vegetation', 'classval': 4, 'is_habitat': True}\n",
    "for j in range(119, 125):\n",
    "    LANDCLASSES[j] = {'name': 'wetland short vegetation', 'classval': 5, 'is_habitat': True}\n",
    "for j in range(125, 149):\n",
    "    LANDCLASSES[j] = {'name': 'weland tree cover', 'classval': 6, 'is_habitat': True}\n",
    "for j in range(200, 208):\n",
    "    LANDCLASSES[j] = {'name': 'open water', 'classval': 7, 'is_habitat': True}\n",
    "LANDCLASSES[241] = {'name': 'snow and ice', 'classval': 8, 'is_habitat': False}\n",
    "LANDCLASSES[241] = {'name': 'cropland', 'classval': 9, 'is_habitat': False}\n",
    "LANDCLASSES[250] = {'name': 'built up', 'classval': 10, 'is_habitat': False}\n",
    "LANDCLASSES[254] = {'name': 'ocean', 'classval': 11, 'is_habitat': False}\n",
    "\n",
    "for j in range(256):\n",
    "    if not j in list(LANDCLASSES.keys()):\n",
    "        LANDCLASSES[j] = {'name': 'nodata', 'classval': 0, 'is_habitat': False}\n",
    "        \n",
    "froms = list(range(256))\n",
    "tos = [LANDCLASSES[j]['classval'] for j in froms]        \n",
    "LCLUC2000 = ee.Image('projects/glad/GLCLU2020/LCLUC_2000').remap(froms, tos, 0)\n",
    "LCLUC2020 = ee.Image('projects/glad/GLCLU2020/LCLUC_2020').remap(froms, tos, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1dbe1-022c-4f45-9f33-2c60004beef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to habitat/nonhabitat\n",
    "froms = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "tos = [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "habitat_2000 = LCLUC2000.remap(froms, tos, 0)\n",
    "habitat_2020 = LCLUC2020.remap(froms, tos, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3acf964-c1d5-4ce9-ad48-f9a9506d6155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_habitat = habitat_2000.eq(0).multiply(habitat_2020)\n",
    "new_habitat_types = LCLUC2020.updateMask(new_habitat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019bffd-2c03-44d2-b886-57dcb602e300",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitat2020_types = LCLUC2020.updateMask(habitat_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9da62de-50c7-422b-a6ca-f2fe58a8177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind(fc):\n",
    "    count_new_habitat_types = new_habitat_types.reduceRegions(**{\n",
    "        'reducer': ee.Reducer.countDistinctNonNull(),\n",
    "        'collection': fc,\n",
    "        'scale': 30\n",
    "    })\n",
    "    count_2020_habitat_types = habitat2020_types.reduceRegions(**{\n",
    "        'reducer': ee.Reducer.countDistinctNonNull(),\n",
    "        'collection': fc,\n",
    "        'scale': 30\n",
    "    })\n",
    "    ind = (geemap.ee_to_pandas(count_new_habitat_types)['count']) / (geemap.ee_to_pandas(count_2020_habitat_types)['count'])\n",
    "    return ind\n",
    "\n",
    "def get_count(fc):\n",
    "    count_new_habitat_types = new_habitat_types.reduceRegions(**{\n",
    "        'reducer': ee.Reducer.countDistinctNonNull(),\n",
    "        'collection': fc,\n",
    "        'scale': 30\n",
    "    })\n",
    "    return (geemap.ee_to_pandas(count_new_habitat_types)['count'])\n",
    "\n",
    "def get_total(fc):\n",
    "    count_2020_habitat_types = habitat2020_types.reduceRegions(**{\n",
    "        'reducer': ee.Reducer.countDistinctNonNull(),\n",
    "        'collection': fc,\n",
    "        'scale': 30\n",
    "    })\n",
    "    return (geemap.ee_to_pandas(count_2020_habitat_types)['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab64cd3-d7f0-4503-b6a5-e1239186f44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for i in range(0,len(boundary_georef)):\n",
    "    for boundary_name in ['aoi_boundary_name', 'units_boundary_name']:\n",
    "        if type(boundary_georef.loc[i, boundary_name]) != float: # sometimes boundary_id is nan\n",
    "            boundary_id = boundary_georef.loc[i, 'geo_name']+'-' + boundary_georef.loc[i, boundary_name]\n",
    "            print(boundary_id)\n",
    "            boundary_path = aws_s3_dir + boundary_ext +'boundary-'+boundary_id+'.geojson'\n",
    "            boundary_geo = requests.get(boundary_path).json()\n",
    "            temp_gdf = gpd.GeoDataFrame.from_features(boundary_geo)\n",
    "                        \n",
    "            boundary_geo_ee = geemap.geojson_to_ee(boundary_geo)\n",
    "            temp_gdf = gpd.GeoDataFrame.from_features(boundary_geo)\n",
    "            #if True or boundary_name == 'aoi_boundary_name':  # Calculates naturalarea for aoi, uses it for all unit-of-analysis calculations.\n",
    "               \n",
    "            temp_gdf['LND_5_numberofHabitatTypesRestoredby2020'] = get_ind(boundary_geo_ee).fillna(-9999)\n",
    "            all_results.append(temp_gdf.copy())\n",
    "            outp = pd.concat(all_results, axis=0)[['geo_id', 'geo_level', 'geo_name', 'geo_parent_name', 'LND_5_numberofHabitatTypesRestoredby2020']]\n",
    "            outp.to_csv(OUTPUT_FILENAME)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197340a0-dddc-419a-91a0-1df1c2a1b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedcities = pd.read_csv(OUTPUT_FILENAME)\n",
    "processedcities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c318b30-f027-4043-8c99-cd8972a93922",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Merge with indicator table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb0cf8-9ec1-48d0-bf04-3a029ef0f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read indicator table\n",
    "cities_indicators = pd.read_csv(aws_s3_dir +'/'+ indicators_file_aws)\n",
    "cities_indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3982d07b-06b1-4656-9889-a876871f4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_indicators(indicator_table, new_indicator_table, indicator_name):\n",
    "    if indicator_name in indicator_table.columns:\n",
    "        print(\"replace with new calculations\")\n",
    "        indicator_table.drop(indicator_name, inplace=True, axis=1)\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left')\n",
    "    else:\n",
    "        print(\"add new indicators\")\n",
    "        cities_indicators_df = indicator_table.merge(new_indicator_table[[\"geo_id\",indicator_name]], \n",
    "                                                     on='geo_id', \n",
    "                                                     how='left')\n",
    "    return(cities_indicators_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3409fc-b7f6-4c97-a9d2-7f07e13c6534",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged = merge_indicators(indicator_table = cities_indicators,\n",
    "                                            new_indicator_table = processedcities,\n",
    "                                            indicator_name = 'LND_5_numberofHabitatTypesRestoredby2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e94e8-6371-4ebb-96d0-b47f18a0c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_indicators_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ad996-9b82-4fd3-a7d4-31a8f6c2f7e2",
   "metadata": {},
   "source": [
    "## Upload in aws s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb0c3f-ce17-4845-81ba-230dd37af764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to s3\n",
    "aws_credentials = pd.read_csv('/home/jovyan/PlanetaryComputerExamples/aws_credentials.csv')\n",
    "aws_key = aws_credentials.iloc[0]['Access key ID']\n",
    "aws_secret = aws_credentials.iloc[0]['Secret access key']\n",
    "\n",
    "s3 = boto3.resource(\n",
    "    service_name='s3',\n",
    "    aws_access_key_id=aws_key,\n",
    "    aws_secret_access_key=aws_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cdc353-4533-4a8c-a404-757c334f32de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to aws\n",
    "key_data = indicators_file_aws\n",
    "cities_indicators_merged.to_csv(\n",
    "    f\"s3://{bucket_name}/{key_data}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": aws_key,\n",
    "        \"secret\": aws_secret\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff024c-812f-4680-a82c-aa22cb876d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it public\n",
    "object_acl = s3.ObjectAcl(bucket_name,key_data)\n",
    "response = object_acl.put(ACL='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33deb98-4f14-4f7b-bc82-f65bbf1ef8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
